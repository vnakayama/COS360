{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COS360 Otimização 2020/2 - Trabalho final\n",
    "### Paulo Sanz e Valentina Nakayama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumário\n",
    "\n",
    "* [Introdução](#Introdução)\n",
    "* [Bibliotecas](#Introdução)\n",
    "* [Funções Auxiliares](#Funções-auxiliares)\n",
    "* [Análise da Função](#Análise-da-função)\n",
    "* [Métodos Minimizadores](#Métodos-minimizadores)\n",
    "* [Resultados](#Resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo deste trabalho é realizar um estudo exploratório da função dada, e também implementar três métodos de minimização estudados em aula, com a busca de Armijo, criando-se tabelas para comparação de tais métodos.\n",
    "\n",
    "A função dada e o domínio são dados abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{min   }\\ \\ f(x) = -e^{-x_1^2-x_2^2} \\\\ \\text{s.a.   }\\ \\ \\  x \\in \\Omega = \\!R_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O problema é irrestrito, pois $x \\in \\!R_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_square_matrix(a, b, c, d):\n",
    "    det = a * d - b * c\n",
    "    return d / det, -1 * b / det, -1 * c / det, a / det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_defined(x):\n",
    "    if np.array_equal(x, x.T):\n",
    "        try:\n",
    "            np.linalg.cholesky(x)\n",
    "            return True\n",
    "        except np.linalg.LinAlgError:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_matrix(x, y):\n",
    "    return x * 2 * math.exp(-1 * (x**2 + y**2)), y * 2 * math.exp(-1 * (x**2 + y**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_matrix(x, y):\n",
    "    h = np.array([[(2 - 4 * x **2) * math.exp(-1 * (x**2 + y**2)) ,  - 4 * x * y * math.exp(-1 * (x**2 + y**2))],\n",
    "                  [-4 * x * y * math.exp(-1 * (x**2 + y**2)), (2 - 4 * y **2) * math.exp(-1 * (x**2 + y**2)) ]])\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def armijo_search(x, y, direction_x, direction_y):\n",
    "    growth = 0.8\n",
    "    control = 0.25\n",
    "    dot = lambda grad_x, grad_y, d_x, d_y: grad_x * d_x + grad_x * d_y\n",
    "    \n",
    "    grad_x, grad_y = gradient_matrix(x, y)\n",
    "    num_calls = 0\n",
    "    step = 1\n",
    "    while (function(x + step * direction_x, y + step * direction_y)\n",
    "        > function(x, y) + control * step * dot(grad_x, grad_y, direction_x, direction_y)):\n",
    "            step *= growth\n",
    "            num_calls += 1\n",
    "    \n",
    "    return step, num_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(x, y, minimize_function, search_function):\n",
    "    new_x, new_y, iteration_count, num_calls = minimize_function(x, y, search_function)\n",
    "    value = function(new_x, new_y)\n",
    "    return [x, y, iteration_count, num_calls, new_x, new_y, value, -2 - value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise da função"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Faça um pequeno estudo para um melhor entendimento do comportamento de suas funções.  Exemplo:  Pontos críticos, convexidade, existência de ótimo, plotar, etc. Implemente o algoritmo para obter o(s) ponto(s) mínimo(s), caso exista(m), das funções acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(x, y):\n",
    "    return -1 * math.exp(-1 * (x**2 + y**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y = np.arange(-3, 3, 0.05)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "z_array = np.array([function(a, b) for a, b in zip(np.ravel(X), np.ravel(Y))])\n",
    "Z = z_array.reshape(X.shape)\n",
    "\n",
    "fig = plt.figure(figsize=[10.0,10.0])\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X, Y, Z)\n",
    "\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos minimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Critério de parada: máximo de interações, 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método Gradiente\n",
    "\n",
    "blablabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_method(x, y, search_function):\n",
    "    iteration_count = 0\n",
    "    max_iterations = 100\n",
    "    \n",
    "    # We need to iterate over this\n",
    "    max_value = 2 ** 64\n",
    "    min_value = 1 / 2 ** 256\n",
    "    irrelevant_delta = 1 / 2 ** 50\n",
    "    \n",
    "    grad_x, grad_y = gradient_matrix(x, y)\n",
    "    variation_x, variation_y = max_value, max_value\n",
    "\n",
    "    sum_num_calls = 0\n",
    "    \n",
    "    while (iteration_count < max_iterations \n",
    "           and (abs(grad_x) > min_value or abs(grad_y) > min_value)\n",
    "           and abs(variation_x) > irrelevant_delta or abs(variation_y) > irrelevant_delta):\n",
    "            \n",
    "            direction_x, direction_y = -1 * grad_x, -1 * grad_y\n",
    "            step, num_calls = search_function(x, y, direction_x, direction_y)\n",
    "            sum_num_calls += num_calls\n",
    "            \n",
    "            x0, y0 = x, y\n",
    "            x, y = x + step * direction_x, y + step * direction_y\n",
    "            variation_x, variation_y = x - x0, y - y0\n",
    "            iteration_count = iteration_count + 1\n",
    "            gradient = gradient_matrix(x, y)\n",
    "    \n",
    "    return x, y, iteration_count, sum_num_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método de Newton\n",
    "\n",
    "blablabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def newton_method(x, y, search_function):\n",
    "    iteration_count = 0\n",
    "    max_iterations = 100\n",
    "    \n",
    "    max_value = 2 ** 64\n",
    "    min_value = 1 / 2 ** 256\n",
    "    irrelevant_delta = 1 / 2 ** 50\n",
    "    direction_x, direction_y = 0, 0\n",
    "    \n",
    "    grad_x, grad_y = gradient_matrix(x, y)\n",
    "    variation_x, variation_y = max_value, max_value\n",
    "    \n",
    "    sum_num_calls = 0\n",
    "    \n",
    "    while (iteration_count < max_iterations \n",
    "           and (abs(grad_x) > min_value or abs(grad_y) > min_value)\n",
    "           and abs(variation_x) > irrelevant_delta or abs(variation_y) > irrelevant_delta):\n",
    "        \n",
    "            hessian = hessian_matrix(x,y)\n",
    "            \n",
    "            if (pos_defined(hessian)):\n",
    "                \n",
    "                grad = gradient_matrix(x,y)\n",
    "                direction_x, direction_y = -1 * np.dot(inverse_quad_matrix(hessian), grad)\n",
    "                t, num_calls = search(x, y, direction_x, direction_y)\n",
    "                sum_num_calls += num_calls\n",
    "                \n",
    "                x0, y0 = x, y\n",
    "                x, y = [x + t * direction_x, y + t * direction_y]\n",
    "                variation_x, variation_y = x - x0, y - y0\n",
    "                iteration_count += 1\n",
    "                \n",
    "            else:\n",
    "                \n",
    "#                 if (iteration_count == 0):\n",
    "#                     print('Initial Hessian is not positivily defined, stop method.')\n",
    "#                 ele cai aqui toda vez\n",
    "                break\n",
    "    \n",
    "    return x, y, iteration_count, sum_num_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método Quase-Newton\n",
    "\n",
    "blablabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quasi_newton_method(x, y, search_function):\n",
    "    iteration_count = 0\n",
    "    max_iterations = 1000\n",
    "    \n",
    "    grad_x, grad_y = gradient_matrix(x, y)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 5\n",
    "points = [[-1.8385400365595483, 4.359940932133885]] + [[random.uniform(-10.0, 10.0), random.uniform(-10.0, 10.0)] for _ in range(count)]\n",
    "\n",
    "methods = [\n",
    "    {\n",
    "        \"name\": \"Gradient\",\n",
    "        \"func\": gradient_method\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Newton\",\n",
    "        \"func\": newton_method\n",
    "    }\n",
    "#     {\n",
    "#         \"name\": \"Quasi-Newton\",\n",
    "#         \"func\": quasi_newton_method\n",
    "#     }\n",
    "]\n",
    "\n",
    "for method in methods:\n",
    "    lines = [[\"X0\", \"Y0\", \"Iter.\", \"Search Iter.\", \"X Opt.\", \"Y Opt.\", \"Opt. Value\", \"Error\"]]\n",
    "    lines += [generate_results(point[0], point[1], method[\"func\"], armijo_search) for point in points]\n",
    "\n",
    "    print(\"{method_name} Method + Armijo\".format(method_name = method[\"name\"]))\n",
    "\n",
    "    display(HTML('<table><tr>{}</tr></table>'.format(\n",
    "       '</tr><tr>'.join(\n",
    "           '<td>{}</td>'.format('</td><td>'.join(str(val) for val in line)) for line in lines)\n",
    "    )))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
